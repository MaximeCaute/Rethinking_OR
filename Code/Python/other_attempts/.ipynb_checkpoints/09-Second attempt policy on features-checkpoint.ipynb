{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  09 - Learning Policy on Attributes \n",
    "### Attributes from Claudia' simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDEA:: \n",
    "Group vehicles based on their state. Represent states instead of vehicles and make net output location of the desired vehicle  NOT WORKING\n",
    "\n",
    "RIGHT NOW: X is the same but truing to predict position of the vehicle to select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, inp, num_v):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(inp, 200)\n",
    "        self.bn1 = nn.BatchNorm1d(200)\n",
    "        self.fc2 = nn.Linear(200, 200)\n",
    "        self.bn2 = nn.BatchNorm1d(200)\n",
    "        self.d2  = nn.Dropout(p=0.2)\n",
    "        #self.fc3 = nn.Linear(500, 1000)\n",
    "        #self.bn3 = nn.BatchNorm1d(1000)\n",
    "        self.fc5 = nn.Linear(200, 200)\n",
    "        self.bn5 = nn.BatchNorm1d(200)\n",
    "        self.d5  = nn.Dropout(p=0.5)\n",
    "        self.fc6 = nn.Linear(200, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.d2(x)\n",
    "        #x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = F.relu(self.bn5(self.fc5(x)))\n",
    "        #x = self.d5(x)\n",
    "        x = self.fc6(x)\n",
    "        #return F.log_softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_V = 30\n",
    "mini_batch_size = 50\n",
    "#n_epochs=150\n",
    "n_epochs=25\n",
    "\n",
    "tables = list(range(1,95))\n",
    "random.shuffle(tables)\n",
    "\n",
    "\n",
    "train_tables, test_tables, validation_tables = \\\n",
    "tables[:int(len(tables)*0.6)], tables[int(len(tables)*0.6):int(len(tables)*0.9)], tables[int(len(tables)*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-4190c7ded06e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_V\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'params'"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "inp_size = 4 + MAX_V*6\n",
    "\n",
    "model = Net(inp_size, MAX_V)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = optim.SGD(lr=lr)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_train(model, train_table, test_tables, optimizer, criterion, e, train=True):\n",
    "    if train:\n",
    "        TABLES = train_tables\n",
    "        st = 'train'\n",
    "    else:\n",
    "        TABLES = test_tables\n",
    "        st = 'test'\n",
    "    \n",
    "    \n",
    "    sum_loss = 0\n",
    "    acc = []\n",
    "    idx_failures = []\n",
    "\n",
    "    # train data\n",
    "    for k, TABLE in enumerate(TABLES):\n",
    "        data = np.load('./relative_data/data_vector_{}.npy'.format(TABLE), allow_pickle=True).tolist()\n",
    "        data_y = np.load('./relative_data/data_vector_y_{}.npy'.format(TABLE), allow_pickle=True).tolist()\n",
    "\n",
    "        idx = list(data.keys())\n",
    "        #random.shuffle(idx)\n",
    "\n",
    "        for b in range(0, len(idx), mini_batch_size):\n",
    "\n",
    "            t_idx = idx[b:b+mini_batch_size]\n",
    "            \n",
    "            x = np.asarray([np.hstack(data[i]) for i in t_idx])\n",
    "            x_toy = np.asarray([np.array(data[i]) for i in t_idx])\n",
    "            veh = np.hstack([data_y[i] for i in t_idx])\n",
    "            y = [x_toy[i][int(veh[i]) + 1][2:4] for i in range(x_toy.shape[0])] #position of each vehicle to be selected\n",
    "            \n",
    "            #x_set = []\n",
    "            #for i in range(x.shape[0]):\n",
    "                #x_state = [x[i][0][k] for k in range(len(x[i][0]))]\n",
    "                #visited = []\n",
    "                #for j in range(1, x.shape[1]):\n",
    "                #    if x[i][j] not in visited:\n",
    "                #        visited.append(x[i][j])\n",
    "                #        for k in x[i][j]:\n",
    "                #            x_state.append(k)\n",
    "                #x_flat = np.zeros(4 + 6*num_v)\n",
    "                #x_flat[:len(x_state)] = x_state\n",
    "\n",
    "                #x_set.append(x_flat)\n",
    "            #x_set = np.asarray(x_set)  \n",
    "                \n",
    "            train_x = torch.tensor(x).type(torch.FloatTensor)\n",
    "            #train_x = torch.tensor(x_set).type(torch.FloatTensor)\n",
    "            train_y = torch.tensor(y).type(torch.FloatTensor)\n",
    "            \n",
    "            # set gradient to zero\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # compute output\n",
    "            output = model(train_x)\n",
    "            batch_loss = criterion(output, train_y)\n",
    "            \n",
    "            if train:\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            sum_loss = sum_loss + batch_loss.item()\n",
    "                \n",
    "    return sum_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 0:\tTrain loss: 104.1635\tTest loss: 49.8623\n",
      " Epoch 1:\tTrain loss: 90.0460\tTest loss: 49.9659\n",
      " Epoch 2:\tTrain loss: 82.2661\tTest loss: 51.3725\n",
      " Epoch 3:\tTrain loss: 75.3755\tTest loss: 51.6032\n",
      " Epoch 4:\tTrain loss: 70.1278\tTest loss: 53.6894\n",
      " Epoch 5:\tTrain loss: 66.2812\tTest loss: 52.6334\n",
      " Epoch 6:\tTrain loss: 61.2028\tTest loss: 55.1385\n",
      " Epoch 7:\tTrain loss: 59.3846\tTest loss: 54.6079\n",
      " Epoch 8:\tTrain loss: 56.4936\tTest loss: 54.6532\n",
      " Epoch 9:\tTrain loss: 53.0995\tTest loss: 54.9958\n",
      " Epoch 10:\tTrain loss: 50.3803\tTest loss: 56.8821\n",
      " Epoch 11:\tTrain loss: 49.5084\tTest loss: 55.1745\n",
      " Epoch 12:\tTrain loss: 47.6156\tTest loss: 57.9316\n",
      " Epoch 13:\tTrain loss: 45.0893\tTest loss: 57.7246\n",
      " Epoch 14:\tTrain loss: 40.5503\tTest loss: 57.0235\n",
      " Epoch 15:\tTrain loss: 39.9687\tTest loss: 57.6405\n",
      " Epoch 16:\tTrain loss: 37.9767\tTest loss: 58.7515\n",
      " Epoch 17:\tTrain loss: 38.4300\tTest loss: 57.6834\n",
      " Epoch 18:\tTrain loss: 36.9987\tTest loss: 58.1840\n",
      " Epoch 19:\tTrain loss: 33.5094\tTest loss: 59.0459\n",
      " Epoch 20:\tTrain loss: 32.6992\tTest loss: 58.4957\n",
      " Epoch 21:\tTrain loss: 31.0245\tTest loss: 58.6841\n",
      " Epoch 22:\tTrain loss: 29.7379\tTest loss: 60.7963\n",
      " Epoch 23:\tTrain loss: 28.7945\tTest loss: 58.5401\n",
      " Epoch 24:\tTrain loss: 27.9190\tTest loss: 58.6779\n"
     ]
    }
   ],
   "source": [
    "train_loss, acc, test_loss, test_acc, idx_f = [], [], [], [], []\n",
    "for epoch in range(n_epochs):\n",
    "    train_l  = epoch_train(model, train_tables, test_tables, optimizer, criterion, epoch)\n",
    "    test_l  = epoch_train(model, train_tables, test_tables, optimizer, criterion, epoch, train=False)\n",
    "    \n",
    "    print('\\r Epoch {}:\\tTrain loss: {:.4f}\\tTest loss: {:.4f}'.format(epoch, train_l, test_l))\n",
    "    train_loss.append(train_l)\n",
    "    test_loss.append(test_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./relative_data/data_vector_{}.npy'.format(2), allow_pickle=True).tolist()\n",
    "data_y = np.load('./relative_data/data_vector_y_{}.npy'.format(2), allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_v = 30\n",
    "t_idx = idx[0:0+10]\n",
    "x = np.asarray([np.array(data[i]) for i in t_idx])\n",
    "veh = np.hstack([data_y[i] for i in t_idx])\n",
    "y = [x[i][int(veh[i]) + 1][2:4] for i in range(x.shape[0])] #position of each vehicle to be selected\n",
    "            \n",
    "x_set = []\n",
    "for i in range(x.shape[0]):\n",
    "    x_state = [x[i][0][k] for k in range(len(x[i][0]))]\n",
    "    visited = []\n",
    "    for j in range(1, x.shape[1]):\n",
    "        if x[i][j] not in visited:\n",
    "            visited.append(x[i][j])\n",
    "            for k in x[i][j]:\n",
    "                x_state.append(k)\n",
    "    x_flat = np.zeros(4 + 6*num_v)\n",
    "    x_flat[:len(x_state)] = x_state\n",
    "    \n",
    "    x_set.append(x_flat)\n",
    "x_set = np.asarray(x_set)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(x_set).type(torch.FloatTensor)\n",
    "o = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0581,  0.9835],\n",
       "        [ 0.1545, -0.0552],\n",
       "        [-0.5111, -0.5127],\n",
       "        [-0.4340, -0.6575],\n",
       "        [ 0.8728,  0.7165],\n",
       "        [ 0.0400,  0.2524],\n",
       "        [-0.8620, -0.1221],\n",
       "        [-1.7851, -0.9722],\n",
       "        [-0.4549, -0.3879],\n",
       "        [-0.3656, -0.3107]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.asarray([np.asarray(x_state[i]) for i in range(len(x_state))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([-1.90403816, -0.91650271, -0.0466364 , -0.94180787]),\n",
       "       array([0.        , 1.        , 0.89559293, 0.87296133, 0.89559293,\n",
       "       0.87296133]),\n",
       "       array([ 1.        ,  1.        , -2.14819959, -1.1981686 , -1.96096587,\n",
       "       -0.90930048]),\n",
       "       array([ 1.        ,  1.        , -1.94624692, -0.91066306, -0.14577287,\n",
       "       -0.17914932]),\n",
       "       array([ 1.        ,  1.        , -1.84840918, -1.25656512, -0.19057909,\n",
       "        1.12095189]),\n",
       "       array([0.        , 0.        , 0.89559293, 0.87296133, 0.89559293,\n",
       "       0.87296133])], dtype=object)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = list(data.keys())\n",
    "for b in range(0, len(idx), 10):\n",
    "    t_idx = idx[b:b+10]\n",
    "    x = np.asarray([np.array(data[i]) for i in t_idx])\n",
    "    y = np.asarray([data_y[i] for i in t_idx])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = []\n",
    "for i in range(x.shape[0]):\n",
    "    states.append(x[i][int(y[i]) + 1][2:4]) # position of the chosen vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.895592925387986, 0.8729613295638093],\n",
       " [0.895592925387986, 0.8729613295638093],\n",
       " [0.895592925387986, 0.8729613295638093],\n",
       " [-1.960965869434946, -0.9093004769250232],\n",
       " [0.895592925387986, 0.8729613295638093],\n",
       " [0.895592925387986, 0.8729613295638093],\n",
       " [0.895592925387986, 0.8729613295638093],\n",
       " [-2.0243872323871726, -0.9963112925149629],\n",
       " [-2.0518770381718054, -1.21880203572071],\n",
       " [-1.8484091843313626, -1.2565651189936877]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in range(x.shape[1]):\n",
    "    if x[7][i] not in a:\n",
    "        a.append(x[7][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1.8484091843313626,\n",
       "  -1.2565651189936877,\n",
       "  -0.19057908585813527,\n",
       "  1.1209518867351176],\n",
       " [0,\n",
       "  1,\n",
       "  0.895592925387986,\n",
       "  0.8729613295638093,\n",
       "  0.895592925387986,\n",
       "  0.8729613295638093],\n",
       " [1,\n",
       "  1,\n",
       "  -2.1481995860003456,\n",
       "  -1.1981685984672956,\n",
       "  -1.960965869434946,\n",
       "  -0.9093004769250232],\n",
       " [1,\n",
       "  0,\n",
       "  -2.0518770381718054,\n",
       "  -1.21880203572071,\n",
       "  -0.15572980450918536,\n",
       "  -0.25136634565584237],\n",
       " [1,\n",
       "  0,\n",
       "  -2.0243872323871726,\n",
       "  -0.9963112925149629,\n",
       "  -0.19036263069502168,\n",
       "  0.9611400755585784],\n",
       " [0,\n",
       "  0,\n",
       "  0.895592925387986,\n",
       "  0.8729613295638093,\n",
       "  0.895592925387986,\n",
       "  0.8729613295638093]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
