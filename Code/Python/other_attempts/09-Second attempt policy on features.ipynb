{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  09 - Learning Policy on Attributes \n",
    "### Attributes from Claudia' simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDEA:: \n",
    "Group vehicles based on their state. Represent states instead of vehicles and make net output location of the desired vehicle  NOT WORKING\n",
    "\n",
    "RIGHT NOW: X is the same but truing to predict position of the vehicle to select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, inp, num_v):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(inp, 200)\n",
    "        self.bn1 = nn.BatchNorm1d(200)\n",
    "        self.fc2 = nn.Linear(200, 200)\n",
    "        self.bn2 = nn.BatchNorm1d(200)\n",
    "        self.d2  = nn.Dropout(p=0.2)\n",
    "        #self.fc3 = nn.Linear(500, 1000)\n",
    "        #self.bn3 = nn.BatchNorm1d(1000)\n",
    "        self.fc5 = nn.Linear(200, 200)\n",
    "        self.bn5 = nn.BatchNorm1d(200)\n",
    "        self.d5  = nn.Dropout(p=0.5)\n",
    "        self.fc6 = nn.Linear(200, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.d2(x)\n",
    "        #x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = F.relu(self.bn5(self.fc5(x)))\n",
    "        #x = self.d5(x)\n",
    "        x = self.fc6(x)\n",
    "        #return F.log_softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_V = 30\n",
    "mini_batch_size = 50\n",
    "#n_epochs=150\n",
    "n_epochs=25\n",
    "\n",
    "tables = list(range(1,95))\n",
    "random.shuffle(tables)\n",
    "\n",
    "\n",
    "train_tables, test_tables, validation_tables = \\\n",
    "tables[:int(len(tables)*0.6)], tables[int(len(tables)*0.6):int(len(tables)*0.9)], tables[int(len(tables)*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "inp_size = 4 + MAX_V*6\n",
    "\n",
    "model = Net(inp_size, MAX_V)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "#optimizer = optim.SGD(lr=lr)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_train(model, train_table, test_tables, optimizer, criterion, e, train=True):\n",
    "    if train:\n",
    "        TABLES = train_tables\n",
    "        st = 'train'\n",
    "    else:\n",
    "        TABLES = test_tables\n",
    "        st = 'test'\n",
    "    \n",
    "    \n",
    "    sum_loss = 0\n",
    "    acc = []\n",
    "    idx_failures = []\n",
    "\n",
    "    # train data\n",
    "    for k, TABLE in enumerate(TABLES):\n",
    "        data = np.load('./minmax_data/data_vector_{}.npy'.format(TABLE), allow_pickle=True).tolist()\n",
    "        data_y = np.load('./minmax_data/data_vector_y_{}.npy'.format(TABLE), allow_pickle=True).tolist()\n",
    "\n",
    "        idx = list(data.keys())\n",
    "        #random.shuffle(idx)\n",
    "\n",
    "        for b in range(0, len(idx), mini_batch_size):\n",
    "\n",
    "            t_idx = idx[b:b+mini_batch_size]\n",
    "            \n",
    "            x = np.asarray([np.hstack(data[i]) for i in t_idx])\n",
    "            x_toy = np.asarray([np.array(data[i]) for i in t_idx])\n",
    "            veh = np.hstack([data_y[i] for i in t_idx])\n",
    "            y = [x_toy[i][int(veh[i]) + 1][2:4] for i in range(x_toy.shape[0])] #position of each vehicle to be selected\n",
    "            \n",
    "            #x_set = []\n",
    "            #for i in range(x.shape[0]):\n",
    "                #x_state = [x[i][0][k] for k in range(len(x[i][0]))]\n",
    "                #visited = []\n",
    "                #for j in range(1, x.shape[1]):\n",
    "                #    if x[i][j] not in visited:\n",
    "                #        visited.append(x[i][j])\n",
    "                #        for k in x[i][j]:\n",
    "                #            x_state.append(k)\n",
    "                #x_flat = np.zeros(4 + 6*num_v)\n",
    "                #x_flat[:len(x_state)] = x_state\n",
    "\n",
    "                #x_set.append(x_flat)\n",
    "            #x_set = np.asarray(x_set)  \n",
    "                \n",
    "            train_x = torch.tensor(x).type(torch.FloatTensor)\n",
    "            #train_x = torch.tensor(x_set).type(torch.FloatTensor)\n",
    "            train_y = torch.tensor(y).type(torch.FloatTensor)\n",
    "            \n",
    "            # set gradient to zero\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # compute output\n",
    "            output = model(train_x)\n",
    "            batch_loss = criterion(output, train_y)\n",
    "            \n",
    "            if train:\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            sum_loss = sum_loss + batch_loss.item()\n",
    "                \n",
    "    return sum_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 0:\tTrain loss: 11.5997\tTest loss: 4.4596\n",
      " Epoch 1:\tTrain loss: 7.4150\tTest loss: 4.1722\n",
      " Epoch 2:\tTrain loss: 6.4396\tTest loss: 4.1175\n",
      " Epoch 3:\tTrain loss: 5.9107\tTest loss: 4.2358\n",
      " Epoch 4:\tTrain loss: 5.4575\tTest loss: 4.3424\n",
      " Epoch 5:\tTrain loss: 5.2324\tTest loss: 4.3370\n",
      " Epoch 6:\tTrain loss: 5.0300\tTest loss: 4.3423\n",
      " Epoch 7:\tTrain loss: 4.7880\tTest loss: 4.4669\n",
      " Epoch 8:\tTrain loss: 4.5250\tTest loss: 4.4831\n",
      " Epoch 9:\tTrain loss: 4.3696\tTest loss: 4.6900\n",
      " Epoch 10:\tTrain loss: 4.2317\tTest loss: 4.3180\n",
      " Epoch 11:\tTrain loss: 4.1221\tTest loss: 4.3380\n",
      " Epoch 12:\tTrain loss: 3.9372\tTest loss: 4.4184\n",
      " Epoch 13:\tTrain loss: 3.8580\tTest loss: 4.4183\n",
      " Epoch 14:\tTrain loss: 3.7141\tTest loss: 4.7695\n",
      " Epoch 15:\tTrain loss: 3.6883\tTest loss: 4.7370\n",
      " Epoch 16:\tTrain loss: 3.5507\tTest loss: 4.5560\n",
      " Epoch 17:\tTrain loss: 3.4177\tTest loss: 4.3471\n",
      " Epoch 18:\tTrain loss: 3.1426\tTest loss: 4.4884\n",
      " Epoch 19:\tTrain loss: 3.2784\tTest loss: 4.6744\n",
      " Epoch 20:\tTrain loss: 3.0782\tTest loss: 4.6858\n",
      " Epoch 21:\tTrain loss: 2.9358\tTest loss: 4.6059\n",
      " Epoch 22:\tTrain loss: 2.8907\tTest loss: 4.4149\n",
      " Epoch 23:\tTrain loss: 2.8739\tTest loss: 4.6439\n",
      " Epoch 24:\tTrain loss: 2.6935\tTest loss: 4.6063\n"
     ]
    }
   ],
   "source": [
    "train_loss, acc, test_loss, test_acc, idx_f = [], [], [], [], []\n",
    "for epoch in range(n_epochs):\n",
    "    train_l  = epoch_train(model, train_tables, test_tables, optimizer, criterion, epoch)\n",
    "    test_l  = epoch_train(model, train_tables, test_tables, optimizer, criterion, epoch, train=False)\n",
    "    \n",
    "    print('\\r Epoch {}:\\tTrain loss: {:.4f}\\tTest loss: {:.4f}'.format(epoch, train_l, test_l))\n",
    "    train_loss.append(train_l)\n",
    "    test_loss.append(test_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./minmax_data/data_vector_{}.npy'.format(2), allow_pickle=True).tolist()\n",
    "data_y = np.load('./minmax_data/data_vector_y_{}.npy'.format(2), allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_v = 30\n",
    "idx = list(data.keys())\n",
    "t_idx = idx[0:0+10]\n",
    "x = np.asarray([np.array(data[i]) for i in t_idx])\n",
    "veh = np.hstack([data_y[i] for i in t_idx])\n",
    "y = [x[i][int(veh[i]) + 1][2:4] for i in range(x.shape[0])] #position of each vehicle to be selected\n",
    "            \n",
    "x_set = []\n",
    "for i in range(x.shape[0]):\n",
    "    x_state = [x[i][0][k] for k in range(len(x[i][0]))]\n",
    "    visited = []\n",
    "    for j in range(1, x.shape[1]):\n",
    "        if x[i][j] not in visited:\n",
    "            visited.append(x[i][j])\n",
    "            for k in x[i][j]:\n",
    "                x_state.append(k)\n",
    "    x_flat = np.zeros(4 + 6*num_v)\n",
    "    x_flat[:len(x_state)] = x_state\n",
    "    \n",
    "    x_set.append(x_flat)\n",
    "x_set = np.asarray(x_set)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(x_set).type(torch.FloatTensor)\n",
    "o = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2145, -0.0353],\n",
       "        [ 0.5907,  0.3776],\n",
       "        [ 0.5829,  0.3338],\n",
       "        [ 0.6590,  0.5182],\n",
       "        [ 0.7949,  0.5306],\n",
       "        [ 0.5839,  0.6126],\n",
       "        [ 0.6270,  0.6833],\n",
       "        [ 0.3288,  0.4380],\n",
       "        [ 0.4866,  0.3910],\n",
       "        [ 0.6842,  0.4781]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.82, 0.69],\n",
       " [0.82, 0.69],\n",
       " [0.82, 0.69],\n",
       " [0.062, 0.193],\n",
       " [0.82, 0.69],\n",
       " [0.82, 0.69],\n",
       " [0.82, 0.69],\n",
       " [0.046, 0.169],\n",
       " [0.038, 0.107],\n",
       " [0.092, 0.096]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.asarray([np.asarray(x_state[i]) for i in range(len(x_state))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07740418, 0.19111497, 0.56977278, 0.18405474, 0.        ,\n",
       "       1.        , 0.82      , 0.69      , 0.82      , 0.69      ,\n",
       "       1.        , 1.        , 0.013     , 0.113     , 0.062     ,\n",
       "       0.193     , 1.        , 1.        , 0.066     , 0.193     ,\n",
       "       0.543     , 0.397     , 1.        , 1.        , 0.092     ,\n",
       "       0.096     , 0.532     , 0.76      , 0.        , 0.        ,\n",
       "       0.82      , 0.69      , 0.82      , 0.69      ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = list(data.keys())\n",
    "for b in range(0, len(idx), 10):\n",
    "    t_idx = idx[b:b+10]\n",
    "    x = np.asarray([np.array(data[i]) for i in t_idx])\n",
    "    y = np.asarray([data_y[i] for i in t_idx])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = []\n",
    "for i in range(x.shape[0]):\n",
    "    states.append(x[i][int(y[i]) + 1][2:4]) # position of the chosen vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.895592925387986, 0.8729613295638093],\n",
       " [0.895592925387986, 0.8729613295638093],\n",
       " [0.895592925387986, 0.8729613295638093],\n",
       " [-1.960965869434946, -0.9093004769250232],\n",
       " [0.895592925387986, 0.8729613295638093],\n",
       " [0.895592925387986, 0.8729613295638093],\n",
       " [0.895592925387986, 0.8729613295638093],\n",
       " [-2.0243872323871726, -0.9963112925149629],\n",
       " [-2.0518770381718054, -1.21880203572071],\n",
       " [-1.8484091843313626, -1.2565651189936877]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in range(x.shape[1]):\n",
    "    if x[7][i] not in a:\n",
    "        a.append(x[7][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1.8484091843313626,\n",
       "  -1.2565651189936877,\n",
       "  -0.19057908585813527,\n",
       "  1.1209518867351176],\n",
       " [0,\n",
       "  1,\n",
       "  0.895592925387986,\n",
       "  0.8729613295638093,\n",
       "  0.895592925387986,\n",
       "  0.8729613295638093],\n",
       " [1,\n",
       "  1,\n",
       "  -2.1481995860003456,\n",
       "  -1.1981685984672956,\n",
       "  -1.960965869434946,\n",
       "  -0.9093004769250232],\n",
       " [1,\n",
       "  0,\n",
       "  -2.0518770381718054,\n",
       "  -1.21880203572071,\n",
       "  -0.15572980450918536,\n",
       "  -0.25136634565584237],\n",
       " [1,\n",
       "  0,\n",
       "  -2.0243872323871726,\n",
       "  -0.9963112925149629,\n",
       "  -0.19036263069502168,\n",
       "  0.9611400755585784],\n",
       " [0,\n",
       "  0,\n",
       "  0.895592925387986,\n",
       "  0.8729613295638093,\n",
       "  0.895592925387986,\n",
       "  0.8729613295638093]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
